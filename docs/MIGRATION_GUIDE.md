# ðŸš€ AstraKairos Local Data Setup

AstraKairos uses SQLite databases for local catalog access, providing excellent performance for large-scale analysis.

## Quick Setup

### 1. Convert Catalogs to SQLite (One-time)
```bash
# Convert your WDS catalogs to optimized SQLite database
python scripts/convert_catalogs_to_sqlite.py \
  --wds-summary /path/to/wdsweb_summ.txt \
  --orb6 /path/to/orb6.txt \
  --measurements /path/to/wdss_measurements.txt \
  --output /path/to/catalogs.db
```

### 2. Use with AstraKairos
```bash
# Analyze stars using the local database
python -m astrakairos.analyzer.cli stars.csv --source local --database-path catalogs.db
```

## Performance Benefits

| Operation | SQLite Database | Improvement |
|-----------|----------------|-------------|
| **Initialization** | 0.1 seconds | Instant startup |
| **Memory Usage** | 20-50 MB | Constant memory |
| **Query Speed** | 10-50 ms | Sub-second queries |
| **Scalability** | Millions of measurements | No limits |

## Migration Steps

### 1. Convert Catalogs to SQLite (One-time)

```bash
# Convert WDS catalogs to SQLite database
python scripts/convert_catalogs_to_sqlite.py \
  --wds-summary /path/to/wdsweb_summ.txt \
  --orb6 /path/to/orb6.txt \
  --measurements /path/to/wdss_measurements.txt \
  --output /path/to/catalogs.db
```

### 2. Update Code to Use SQLiteDataSource

```python
# Before (LocalFileDataSource)
from astrakairos.data.local_source import LocalFileDataSource

source = LocalFileDataSource(
    wds_filepath="wdsweb_summ.txt",
    orb6_filepath="orb6.txt", 
    wds_measures_filepath="wdss_measurements.txt"
)

# After (SQLiteDataSource)
from astrakairos.data.sqlite_source import SQLiteDataSource

source = SQLiteDataSource("catalogs.db")
```

### 3. API Compatibility

The SQLiteDataSource implements the same interface as LocalFileDataSource:

```python
# All these methods work identically
wds_summary = await source.get_wds_summary("00001+0001")
measurements = await source.get_all_measurements("00001+0001") 
orbital_elements = await source.get_orbital_elements("00001+0001")
physicality = await source.validate_physicality(wds_summary)
```

## Performance Comparison

| Operation | LocalFileDataSource | SQLiteDataSource | Speedup |
|-----------|-------------------|------------------|---------|
| **Initialization** | 10-30 seconds | 0.1 seconds | **100-300x** |
| **Memory Usage** | 3-8 GB | 20-50 MB | **150x less** |
| **Single Query** | 2-5 seconds | 10-50 ms | **50-500x** |
| **1000 Queries** | 30-80 minutes | 30-60 seconds | **60-160x** |

## Large-Scale Analysis Example

```python
from astrakairos.data.sqlite_source import SQLiteDataSource

async def analyze_full_catalog():
    source = SQLiteDataSource("catalogs.db")
    
    # Get statistics
    stats = source.get_catalog_statistics()
    print(f"WDS systems: {stats['wds_summary_count']}")
    print(f"Measurements: {stats['measurements_count']}")
    
    # Process all systems efficiently
    all_wds_ids = source.get_all_wds_ids()
    
    results = []
    for wds_id in all_wds_ids:
        # Each query takes ~10ms instead of 2-5 seconds
        measurements = await source.get_all_measurements(wds_id)
        if measurements and len(measurements) > 10:
            # Perform analysis...
            results.append(analyze_system(measurements))
    
    return results
```

## Configuration Updates

Update your analysis scripts to support both backends:

```python
def create_data_source(config):
    if config.get('use_sqlite', False):
        return SQLiteDataSource(config['sqlite_path'])
    else:
        return LocalFileDataSource(
            wds_filepath=config['wds_file'],
            orb6_filepath=config['orb6_file'],
            wds_measures_filepath=config.get('measurements_file')
        )
```

## Validation

After migration, validate that results are identical:

```python
# Compare results between old and new implementation
async def validate_migration():
    local_source = LocalFileDataSource(...)
    sqlite_source = SQLiteDataSource(...)
    
    test_ids = ["00001+0001", "00013+1234", "15452-0812"]
    
    for wds_id in test_ids:
        local_summary = await local_source.get_wds_summary(wds_id)
        sqlite_summary = await sqlite_source.get_wds_summary(wds_id)
        
        assert local_summary == sqlite_summary
        print(f"âœ“ {wds_id} matches")
```

## Troubleshooting

### Database Corruption
```bash
# Check database integrity
sqlite3 catalogs.db "PRAGMA integrity_check;"

# Rebuild if needed
python scripts/convert_catalogs_to_sqlite.py --force ...
```

### Missing Indexes
```sql
-- Check indexes exist
.indexes

-- Recreate if missing
CREATE INDEX idx_wds_summary_id ON wds_summary(wds_id);
CREATE INDEX idx_measurements_id ON measurements(wds_id);
```

### Performance Issues
```python
# Check table sizes
source = SQLiteDataSource("catalogs.db")
stats = source.get_catalog_statistics()
print(stats)

# Monitor query times
import time
start = time.time()
result = await source.get_all_measurements(wds_id)
print(f"Query time: {time.time() - start:.3f}s")
```
